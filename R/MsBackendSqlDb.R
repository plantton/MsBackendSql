#' @include hidden_aliases.R
NULL

#' @title SQL database based mass spectrometry data backend
#'
#' @aliases class:MsBackendSqlDb MsBackendSqlDb-class
#'
#' @description
#'
#' The `MsBackendSqlDb` is an [MsBackend] backend that keeps all
#' metadata and spectra data (m/z and intensity values) in a single
#' on-disk database table.  This object has a very low memory
#' footprint because only primary keys of the database table are
#' stored in memory, within the object hence making it ideal for
#' representing very large mass spectrometry data sets on computers
#' with limited resources.
#'
#' @section Creating an `MsBackendSqlDb` instance:
#'
#' Like all [MsBackend()] objects, `MsBackendSqlDb` have to be
#' *initialized* with the `backendInitialize()` method. There are three
#' ways to initialize a `MsBackendSqlDb` object by `backendInitialize()` 
#' method. We can either fill the object with data from mass spectrometry
#' files provided with the `files` parameter, or we can pass a `DataFrame`
#' object with metadata and spectra data with the `data` parameter, or 
#' checks if the pre-generated database contains all required data. A 
#' connection to a database (with write access) has to be provided with 
#' the `dbcon` parameter which expects a `DBIConnection` returned by a 
#' call to [dbConnect()]. To fill the database with MS data files (usually
#' mzML files, but all files types supported by the `mzR` package are 
#' allowed), these have to be provided with the `files` parameter. Or, we 
#' can pass a `DataFrame` object to the database through the `DBIConnection`
#' object. This `DataFrame` shall contain the metadata and spectra data parsed
#' by other backends, or generated by by user themselves. Parameter `dbtable` 
#' can be used to optionally specify the database table name that contains,
#' or should contain the data.
#'
#' @param object a `MsBackendSqlDb` object.
#'
#' @param dbcon a `DBIConnection` object to connect to the database. If
#'     not provided, `backendInitialize`method will create a `DBIConnection` 
#'     object in the temporary directory of R.
#'
#' @param files `character` with the file names from which data should
#'     be imported. Only required if the database to which `dbcon`
#'     connects does not already contain the data.
#'
#' @param data For `backendInitialize`: `DataFrame` with spectrum
#'     metadata/data from which data should be imported. This parameter
#'     is the alternative of `files` parameter, only required if the 
#'     database to which `dbcon` connects does not already contain the
#'     data, and the data is not from MS data files.
#'     
#' @param ... Additional arguments.
#'
#' @param dbtable `character(1)` the name of the database table with
#'     the data.  Defaults to `dbtable = "msdata"`.
#'
#' @param peaktable `character(1)` the name of the database table with
#'     peak columns `mz` and `intensity`. Default to `peaktable = "peaktable"`.
#'
#' @param linktable `character(1)` the name of the database table with
#'     labelled peak values `mz` and `intensity`. Default to `linktable =
#'     "linktable"`.
#'
#' @section Implementation notes:
#'
#' The `MsBackendSqlDb` defines the following slots which should not
#' be accessed or changed by the user.
#'
#' @slot dbtable A `character(1)` with the name of the database table
#'     (or view) containing the data.
#'
#' @slot peaktable A`character(1)` with the name of the database table
#'     (or view) containing the peak columns.
#'
#' @slot linktable A `character(1)` with the name of the database table
#'     (or view) containing the mask table for peak columns.  
#' 
#' @slot dbcon A `DBIConnection` with the connection to the database.
#' 
#' @slot modCount An `integer()` that keeps track of each database
#'     writing cycle which would invalidate objects pointing to the
#'     same database. This number has to match between the database
#'     and the object.
#' 
#' @slot rows An `integer()` with the indices (primary keys) of the
#'     data.
#' 
#' @slot columns A `character()` containing the names of the columns
#'     stored in the database.
#'
#' @slot `query` A `DBIResults` object containing SQL query against
#'     the backend.
#'
#' @name MsBackendSqlDb
#' 
#' @section Backend functions:
#' 
#' MsBackendSqlDb extend the base `MsBackend` class from Spectra package.
#' Currently, MsBackendSqlDb supports all the reading functions from `MsBackend` 
#' class. Only specific functions in MsBackendSqlDb will be listed:  
#' 
#' - `reset` the row indices of a MsBackendSqlDb backend after filtering
#'  and/or subsetting operations. MsBackendSqlDb backend utilizes slot `rows`
#'  to mark filtering and subsetting results. The underlying SQLite data tables
#'  won't be influenced by these operations.  
#'
#' @author Chong Tang, Johannes Rainer
#'
#' @export MsBackendSqlDb
#'
#' @exportClass MsBackendSqlDb
#'
#' @examples
#'
#' ## Initialize an MsBackendSqlDb filling it with data from mzML files
#' library(msdata)
#' library(RSQLite)
#' con <- dbConnect(SQLite(), tempfile())
#' fls <- dir(system.file("sciex", package = "msdata"), full.names = TRUE,
#'     pattern = "mzML$")
#' msb <- backendInitialize(MsBackendSqlDb(), dbcon = con, files = fls)
NULL

setClass("MsBackendSqlDb",
         contains = "MsBackend",
         slots = c(dbtable = "character",
                   peaktable = "character",
                   linktable = "character",
                   dbcon = "DBIConnection",
                   modCount = "integer",
                   rows = "integer",
                   columns = "character",
                   query = "DBIResult"),
         prototype = prototype(dbtable = "msdata",
                               readonly = FALSE,
                               modCount = 0L,
                               rows = integer(0),
                               columns = character(0),
                               version = "0.5"))

setValidity("MsBackendSqlDb", function(object) {
    msg <- .valid_db_table_exists(object@dbcon, object@dbtable,
                                  object@peaktable)
    msg <- c(msg, .valid_db_table_columns(object@dbcon, object@columns))
    if (is.null(msg)) TRUE
    else msg
})

#' @importMethodsFrom methods show
#' 
#' @importMethodsFrom S4Vectors head tail
#'
#' @importFrom utils capture.output
#' 
#' @rdname hidden_aliases
setMethod("show", "MsBackendSqlDb", function(object) {
    if (length(object@rows) == 0) {
        cat(class(object), "with", 0, "spectra\n")
    } else if (length(object@rows) > 10) {
    ## get the first 3 and last 3 rows, and print them
    columns <- c("msLevel", "rtime", "scanIndex")
    if (length(setdiff(columns, object@columns)) == 0) {
        qry <- dbSendQuery(object@dbcon,
                           paste0("select msLevel, rtime, scanIndex",
                                " from ", object@dbtable, " where _pkey = ?"))
        rows_print <- c(head(object@rows, 3), 
                        tail(object@rows, 3))
        qry <- dbBind(qry, list(rows_print))
        res <- dbFetch(qry)
        dbClearResult(qry)
        res <- DataFrame(res)
        cat(class(object), "with", length(object@rows), "spectra\n")
        txt <- capture.output(print(res))
        ## Use ellipses to split the head and tails of output string
        txt_prt <- c(txt[-1][1:5],
                     "...     ...       ...       ...",
                     txt[-1][6:8])
        ## Replace the index numbers with correct row numbers
        txt_prt[7] <- gsub("^[0-9]\\s\\s\\s", toString(length(object) - 2), 
                           txt_prt[7])
        txt_prt[8] <- gsub("^[0-9]\\s\\s\\s", toString(length(object) - 1), 
                           txt_prt[8])
        txt_prt[9] <- gsub("^[0-9]\\s\\s\\s", toString(length(object)), 
                           txt_prt[9])
        cat(txt_prt, sep = "\n")
        sp_cols <- spectraVariables(object)
        cat(" ...", length(sp_cols) - 3, "more variables/columns.\n")
    } else {
        return("Columns missing from database.")
      }
    } else {
        spd <- spectraData(object, c("msLevel", "rtime", "scanIndex"))
        cat(class(object), "with", nrow(spd), "spectra\n")
        txt <- capture.output(print(spd))
        cat(txt[-1], sep = "\n")
        sp_cols <- spectraVariables(object)
        cat(" ...", length(sp_cols) - 3, "more variables/columns.\n")
    }
})

#' @rdname MsBackendSqlDb
#'
#' @importMethodsFrom Spectra backendInitialize
#'
#' @importFrom DBI dbIsValid dbGetQuery
#'
#' @importFrom methods is
#'
#' @exportMethod backendInitialize
setMethod("backendInitialize", signature = "MsBackendSqlDb",
          function(object, files = character(), data = DataFrame(), 
                   ..., dbcon, dbtable = "msdata", peaktable = "peaktable",
                   linktable = "linktable") {
    if (missing(dbcon) || !dbIsValid(dbcon)) {
        slot(object, "dbcon", check = FALSE) <- dbConnect(RSQLite::SQLite(), 
                                                     tempfile(fileext = ".db"))
    } else { 
        slot(object, "dbcon", check = FALSE) <- dbcon
    }
    if (is.data.frame(data))
        data <- DataFrame(data)
    if (!is(data, "DataFrame"))
        stop("'data' is supposed to be a 'DataFrame' with ",
             "spectrum data")
    pkey <- "_pkey"
    object@dbtable <- dbtable
    object@peaktable <- peaktable
    object@linktable <- linktable
    ## `data` can also be a `data.frame`
    if (nrow(data)) {
        data$dataStorage <- "<db>"
        .write_data_to_db(data, object@dbcon, dbtable = dbtable)
        ## Since we use `dbAppendTable` to write new data into SQLite db,
        ## The newly appended data will be at the end of the `msdata` table,
        ## The code below uses SQL statement to fetch the last `nrow(data)`
        ## _pkey as object@rows
        res <- dbGetQuery(object@dbcon, paste0("SELECT * FROM (SELECT ",
                          pkey, " FROM ", dbtable, " ORDER BY ", pkey, 
                          " DESC LIMIT ", nrow(data), ") ORDER BY ", pkey,
                          " ASC"))
        ## res is a data frame, we convert it into integer vector
        object@rows <- as.integer(res[, 1])
        } else {
    if (length(files)) {
        for (i in 1:length(files)) {
            hdr <- Spectra:::.mzR_header(files[[i]])
            hdr <- as.data.frame(hdr)
            hdr$dataOrigin <- files[[i]]
            hdr$dataStorage <- "<db>"
            missingCol <- setdiff(names(Spectra:::.SPECTRA_DATA_COLUMNS),
                              names(hdr))
            missingCol <- missingCol[!missingCol %in% c("mz", "intensity")]
            if (length(missingCol) > 0)
                hdr[missingCol] <- NA
            hdr <- as.data.frame(hdr)
            if (!dbExistsTable(dbcon, dbtable)) {
                flds <- dbDataType(dbcon, hdr)
                .sps_mainCol <- Spectra:::.SPECTRA_DATA_COLUMNS
                .sps_num_col <- names(.sps_mainCol)[.sps_mainCol %in% "numeric"]
                flds[names(flds) %in% .sps_num_col] <- "REAL"
                flds[names(flds)[flds %in% "DOUBLE"]] <- "REAL"
                if (inherits(dbcon, "SQLiteConnection"))
                    flds <- c(flds, `_pkey` = "INTEGER PRIMARY KEY")
                else stop(class(dbcon)[1], " connections are not yet supported.")
                qr <- paste0("create table '", dbtable, "' (",
                             paste(paste0("'", names(flds), "'"), flds,
                             collapse = ", "), ")")
                res <- dbExecute(conn = dbcon, qr)            
            }
            dbWriteTable(conn = dbcon, name = dbtable,
                         hdr, append = TRUE)
            pks <- Spectra:::.mzR_peaks(files[[i]], hdr$scanIndex)
            rm(hdr)
            if (!dbExistsTable(dbcon, peaktable)) {            
                qr <- paste0("CREATE TABLE ", peaktable, 
                             " (`_peakpkey` INTEGER PRIMARY KEY, ",
                             "`mz` REAL, `intensity` REAL, `pkey` INTEGER)")
                res <- dbExecute(conn = dbcon, qr)
            }
            .naMatrix <- matrix(NA, nrow = 1, ncol = 2)
            dimnames(.naMatrix)[[2]] <- c("mz", "intensity")
            pks <- lapply(pks,
                          function(x)
                              if (length(x) == 0) {x <- .naMatrix} else x)
            .pkskey <- seq_along(pks)
            .maxPkey <- dbGetQuery(dbcon,
                                       "SELECT MAX(pkey) FROM peaktable")
            if (is.na(.maxPkey[1, 1]))
                .maxPkey[1, 1] <- 0L
            .pkskey <- .pkskey + .maxPkey[1, 1]
            pks <- base::Map(function(x, pkey) cbind(x, pkey), pks, .pkskey)
            pks <- do.call(rbind, pks)
            pks <- as.data.frame(pks)
            dbWriteTable(conn = dbcon, name = peaktable,
                     pks, append = TRUE)
            rm(pks)
        }
        qr1 <- paste0("CREATE TABLE ", "linktable", 
                     " (_peakpkey INTEGER PRIMARY KEY, ",
                      "pkey INTEGER, filtered INTEGER DEFAULT 1)")
        res <- dbExecute(conn = dbcon, qr1)
        qr2 <- paste0("INSERT INTO linktable (pkey) ",
                      "SELECT pkey FROM ", peaktable)
        res <- dbSendStatement(dbcon, qr2)
        ## Use the same way to fetch the last `sum_idx` _pkeys
        res <- dbGetQuery(object@dbcon, paste0("SELECT MAX(", pkey, ") FROM ",
                                               dbtable))
        object@rows <- as.integer(1:res[1, 1])
    } else {
        object@rows <- dbGetQuery(
            object@dbcon, paste0("select ", pkey, " from ", 
                                 dbtable))[, pkey]
    } }
    msg <- .valid_db_table_columns(object@dbcon, dbtable, peaktable)
    if (length(msg)) stop(msg)
    cns <- colnames(dbGetQuery(object@dbcon, paste0("select * from ",
                                             dbtable, " limit 2")))
    object@columns <- cns[cns != pkey]
    object@query <- dbSendQuery(
        object@dbcon, paste0("select ? from ", dbtable, " where ",
                      pkey, "= ?"))
    object
})

#' `backendMerge` method for `MsBackendSqlDb` class. When a `dbcon` is provided,
#' a new `MsBackendSqlDb` instance will be created; the dbtable from `object` 
#' will be inserted into the newly created `MsBackendSqlDb` instance, using 
#' `ATTACH` SQL statement. Or if `dbcon` is missing, the dbtable from other 
#' `object` will be inserted into this `object` using the same schema migration
#' mechanism.
#' 
#' @param dbcon a `DBIConnection` object to connect to the database.
#' 
#' @importMethodsFrom Spectra backendMerge
#' 
#' @exportMethod backendMerge
#'
#' @rdname hidden_aliases
setMethod("backendMerge", "MsBackendSqlDb", function(object, ..., dbcon) {
    object <- unname(c(object, ...))
    ## If `MsBackendSqlDb` has no mz values, the list will not merge it
    object <- object[lengths(object) > 0]
    res <- suppressWarnings(.combine_backend_SqlDb(object, dbcon))
    res
})

## Data accessors
#' @importMethodsFrom Spectra acquisitionNum
#'
#' @rdname hidden_aliases
#' 
#' @importMethodsFrom ProtGenerics acquisitionNum
setMethod("acquisitionNum", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "acquisitionNum")
})

#' @rdname hidden_aliases
#' 
#' @importMethodsFrom ProtGenerics centroided
setMethod("centroided", "MsBackendSqlDb", function(object) {
    as.logical(.get_db_data(object, "centroided"))
})

#' @rdname hidden_aliases
#' 
#' @importMethodsFrom ProtGenerics collisionEnergy
setMethod("collisionEnergy", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "collisionEnergy")
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics dataOrigin
setMethod("dataOrigin", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "dataOrigin")
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics dataStorage
setMethod("dataStorage", "MsBackendSqlDb", function(object) {
    rep("<db>", length(object@rows))
})

#' @exportMethod intensity
#' 
#' @importMethodsFrom ProtGenerics intensity
#' 
#' @rdname hidden_aliases
setMethod("intensity", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "intensity")
})

#' @rdname hidden_aliases
#' 
#' @importFrom MsCoreUtils vapply1d
#'
#' @importMethodsFrom ProtGenerics ionCount
setMethod("ionCount", "MsBackendSqlDb", function(object) {
    vapply1d(intensity(object), sum, na.rm = TRUE)
})

#' @rdname hidden_aliases
#' @importFrom MsCoreUtils vapply1l
#'
#' @importMethodsFrom ProtGenerics isCentroided
setMethod("isCentroided", "MsBackendSqlDb", function(object, ...) {
    vapply1l(peaksData(object), Spectra:::.peaks_is_centroided)
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom S4Vectors isEmpty
setMethod("isEmpty", "MsBackendSqlDb", function(x) {
    lengths(intensity(x)) == 0
})

#' @importMethodsFrom Spectra isolationWindowLowerMz
#' 
#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics isolationWindowLowerMz
setMethod("isolationWindowLowerMz", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "isolationWindowLowerMz")
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics isolationWindowTargetMz
setMethod("isolationWindowTargetMz", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "isolationWindowTargetMz")
})

#' @importMethodsFrom Spectra isolationWindowUpperMz
#'
#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics isolationWindowUpperMz
setMethod("isolationWindowUpperMz", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "isolationWindowUpperMz")
})

#' @rdname hidden_aliases
setMethod("length", "MsBackendSqlDb", function(x) {
    length(x@rows)
})

#' @rdname hidden_aliases
setMethod("lengths", "MsBackendSqlDb", function(x, use.names = FALSE) {
    lengths(mz(x))
})

#' @importMethodsFrom Spectra msLevel
#'
#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics msLevel
setMethod("msLevel", "MsBackendSqlDb", function(object, ...) {
    .get_db_data(object, "msLevel")
})

#' @exportMethod mz
#' 
#' @importMethodsFrom ProtGenerics mz
#' 
#' @rdname hidden_aliases
setMethod("mz", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "mz")
})

#' @importMethodsFrom Spectra peaksData
#' 
#' @exportMethod peaksData
#'
#' @rdname hidden_aliases
setMethod("peaksData", "MsBackendSqlDb", function(object) {
    mapply(cbind, mz = mz(object), intensity = intensity(object),
           SIMPLIFY = FALSE, USE.NAMES = FALSE)
})


#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics polarity
setMethod("polarity", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "polarity")
})

#' @importMethodsFrom Spectra precScanNum
#'
#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics precScanNum
setMethod("precScanNum", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "precScanNum")
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics precursorCharge
setMethod("precursorCharge", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "precursorCharge")
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics precursorIntensity
setMethod("precursorIntensity", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "precursorIntensity")
})

#' @importMethodsFrom Spectra precursorMz
#'
#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics precursorMz
setMethod("precursorMz", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "precursorMz")
})

#' @importMethodsFrom Spectra reset
#'
#' @rdname hidden_aliases
setMethod("reset", "MsBackendSqlDb", function(object) {
    .reset_row_indices(object)
})

#' @importMethodsFrom Spectra rtime
#'
#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics rtime
setMethod("rtime", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "rtime")
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics scanIndex
setMethod("scanIndex", "MsBackendSqlDb", function(object) {
    .get_db_data(object, "scanIndex")
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics smoothed
setMethod("smoothed", "MsBackendSqlDb", function(object) {
    results <- .get_db_data(object, "smoothed")
    if (identical(results, "Columns missing from database.")) {
        return("Columns missing from database.")
    } else {
        as.logical(results)
    }
})

#' @rdname hidden_aliases
#'
#' @importFrom methods as
#'
#' @importFrom S4Vectors SimpleList
#' 
#' @importMethodsFrom Spectra spectraData
#' 
#' @importMethodsFrom DBI dbListFields
#' 
#' @exportMethod spectraData
setMethod("spectraData", "MsBackendSqlDb",
          function(object, columns = spectraVariables(object)) {
    res <- .get_db_data(object, columns)
    ## According to the limitation of SQLite, some of the column types
    ## are missing from the returning values, such as boolean/logical values
    ## We have to change these column types to the correct ones.
    colsToChange <- names(res)[names(res) %in% 
                                 names(Spectra:::.SPECTRA_DATA_COLUMNS)]
    colsToChange <- colsToChange[!colsToChange %in% c("mz", "intensity")]
    for(i in colsToChange){
        class(res[, i]) <- Spectra:::.SPECTRA_DATA_COLUMNS[i]
        if (Spectra:::.SPECTRA_DATA_COLUMNS[i] == "logical")
            res[, i] <- ifelse(res[, i] == 0, FALSE, TRUE)
    }
    res
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics spectraNames
setMethod("spectraNames", "MsBackendSqlDb",
          function(object) NULL)

#' @importMethodsFrom ProtGenerics spectraVariables
#' 
#' @importMethodsFrom DBI dbListFields
#' 
#' @exportMethod spectraVariables
#' 
#' @rdname hidden_aliases
setMethod("spectraVariables", "MsBackendSqlDb", function(object) {
    dbfields <- dbListFields(object@dbcon, object@dbtable)
    dbfields <- dbfields[!(dbfields %in% "_pkey")]
    unique(c(names(Spectra:::.SPECTRA_DATA_COLUMNS), dbfields))
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics tic
setMethod("tic", "MsBackendSqlDb", function(object, initial = TRUE) {
    if (initial) {
      if (any(dbListFields(object@dbcon, object@dbtable) == "totIonCurrent"))
        .get_db_data(object, "totIonCurrent")
      else rep(NA_real_, times = length(object))
    }   else vapply1d(intensity(object), sum, na.rm = TRUE)
})

#' @rdname hidden_aliases
setMethod("$", signature = "MsBackendSqlDb", 
          function(x, name) {
              res <- .get_db_data(x, name[1])
              res 
})


#' @rdname hidden_aliases
#' 
setReplaceMethod("$", "MsBackendSqlDb", function(x, name, value) {
    if (!(length(value) == length(x)))
        stop("Provided values has different length than the object.") 
    if (name %in% spectraVariables(x)) {
        x <- .update_db_table_columns(x, name, value)
    } else {
        x <- .insert_db_table_columns(x, name, value)
    }
    x
})

#### ---------------------------------------------------------------------------
##
##                      FILTERING AND SUBSETTING
##
#### ---------------------------------------------------------------------------

#' @importMethodsFrom S4Vectors [
#'
#' @importFrom MsCoreUtils i2index
#'
#' @rdname hidden_aliases
setMethod("[", "MsBackendSqlDb", function(x, i, j, ..., drop = FALSE) {
    .subset_backend_SqlDb(x, i)
})

#' @rdname hidden_aliases
setMethod("split", "MsBackendSqlDb", function(x, f, drop = FALSE, ...) {
    if (!is.factor(f))
        f <- as.factor(f)
    idx <- split(seq_along(x@rows), f, ...)
    output <- vector(length = length(idx), mode = "list")
    for (i in seq_along(idx)) {
        slot(x, "rows", check = FALSE) <- idx[[i]]
        output[[i]] <- x
    }
    output
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterAcquisitionNum
setMethod("filterAcquisitionNum", "MsBackendSqlDb",
          function(object, n = integer(), dataStorage = character(),
                   dataOrigin = character()) {
    if (!length(n) || !length(object)) return(object)
    if (!is.integer(n)) stop("'n' has to be an integer representing the ",
                                     "acquisition number(s) for sub-setting")
    sel_file <- .sel_file_sql(object, dataStorage, dataOrigin)
    dbExecute(object@dbcon, paste0("CREATE TEMPORARY TABLE TEMPKEY (",
                                       "_pkey INTEGER PRIMARY KEY)"))
    rs <- dbSendStatement(object@dbcon, paste0("INSERT INTO TEMPKEY (_pkey) ",
                                               "SELECT _pkey FROM ",
                                               object@dbtable,
                                               " WHERE _pkey = $pkey"))
    dbBind(rs, list(pkey = object@rows))
    dbClearResult(rs)
    dbExecute(object@dbcon, paste0("CREATE TEMPORARY TABLE TEMAcqNUM (",
                                   "ACQNUM INTEGER)"))
    dbWriteTable(object@dbcon, "TEMAcqNUM",
                 data.frame(ACQNUM = n), append = TRUE)
    acq_pkey <- dbGetQuery(object@dbcon,
                          paste0("SELECT DISTINCT ", object@dbtable,
                              "._pkey FROM TEMPKEY INNER JOIN ", object@dbtable,
                              " ON TEMPKEY._pkey = ", object@dbtable, "._pkey ",
                              "INNER JOIN TEMAcqNUM ON TEMAcqNUM.ACQNUM = ",
                              object@dbtable,
                              ".acquisitionNum ORDER BY ", object@dbtable,
                              "._pkey"))
    dbExecute(object@dbcon, "DROP TABLE IF EXISTS TEMPKEY")
    dbExecute(object@dbcon, "DROP TABLE IF EXISTS TEMAcqNUM")        
    sel_acq <- object@rows %in% acq_pkey[, 1] & sel_file
    object@rows <- object@rows[sel_acq | !sel_file]
    object        
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterDataOrigin
setMethod("filterDataOrigin", "MsBackendSqlDb",
          function(object, dataOrigin = character()) {
    if (length(dataOrigin)) {
        dbExecute(object@dbcon, paste0("CREATE TEMPORARY TABLE TEMPSTR (",
                                "_pkey INTEGER PRIMARY KEY, dataOrigin TEXT)"))
        rs <- dbSendStatement(object@dbcon,
                              paste0("INSERT INTO TEMPSTR (_pkey, dataOrigin) ",
                                     "SELECT _pkey, dataOrigin FROM ",
                                     object@dbtable,
                                     " WHERE (_pkey = $pkey)",
                                     " AND (dataOrigin IN ('",
                                     paste(dataOrigin, collapse = "', '"),
                                     "'))"))
        dbBind(rs, list(pkey = object@rows))
        dbClearResult(rs)
        res <- dbGetQuery(object@dbcon,
                         paste0("SELECT TEMPSTR._pkey FROM TEMPSTR INNER JOIN ",
                                 object@dbtable,
                                " WHERE TEMPSTR._pkey = ", object@dbtable,
                                "._pkey AND (TEMPSTR.dataOrigin IN ('",
                                paste(dataOrigin, collapse = "', '"),
                                "')) ORDER BY CASE TEMPSTR.dataOrigin",
                                paste(" WHEN '", dataOrigin,
                                      "' THEN ", seq_along(dataOrigin),
                                      collapse = " ", sep = ""), " END"))
        dbExecute(object@dbcon, "DROP TABLE IF EXISTS TEMPSTR")
        object@rows <- res[, 1]
        object
    } else object
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterDataStorage
setMethod("filterDataStorage", "MsBackendSqlDb",
          function(object, dataStorage = character()) {
    ## Note: the current version using SQLite, only has one storage file  
    if (length(dataStorage)) {
        dbExecute(object@dbcon, paste0("CREATE TEMPORARY TABLE TEMPSTR (",
                                "_pkey INTEGER PRIMARY KEY, dataStorage TEXT)"))
        rs <- dbSendStatement(object@dbcon,
                              paste0("INSERT INTO TEMPSTR (_pkey, dataStorage) ",
                                     "SELECT _pkey, dataStorage FROM ",
                                     object@dbtable,
                                     " WHERE (_pkey = $pkey)",
                                     " AND (dataStorage IN ('",
                                     paste(dataStorage, collapse = "', '"),
                                     "'))"))
        dbBind(rs, list(pkey = object@rows))
        dbClearResult(rs)
        res <- dbGetQuery(object@dbcon,
                         paste0("SELECT TEMPSTR._pkey FROM TEMPSTR INNER JOIN ",
                                 object@dbtable,
                                " WHERE TEMPSTR._pkey = ", object@dbtable,
                                "._pkey AND (TEMPSTR.dataStorage IN ('",
                                paste(dataStorage, collapse = "', '"),
                                "')) ORDER BY CASE TEMPSTR.dataStorage",
                                paste(" WHEN '", dataStorage,
                                      "' THEN ", seq_along(dataStorage),
                                      collapse = " ", sep = ""), " END"))
        dbExecute(object@dbcon, "DROP TABLE IF EXISTS TEMPSTR")
        object@rows <- res[, 1]
        object    
    } else object
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterEmptySpectra
setMethod("filterEmptySpectra", "MsBackendSqlDb", function(object) {
    if (!length(object)) return(object)
    object@rows <- object@rows[as.logical(lengths(object))]
    object
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom Spectra filterMzRange
setMethod("filterMzRange", "MsBackendSqlDb",
          function(object, mz = numeric(), msLevel. = c(1L, 2L, 3L)) {
    if (!length(object)) return(object)
    mz <- range(mz)
    dbExecute(dbcon, "DROP TABLE IF EXISTS TEMPKEY")
    dbExecute(dbcon, paste0("CREATE TEMPORARY TABLE TEMPKEY (",
                            "_pkey INTEGER PRIMARY KEY)"))
    rs <- dbSendStatement(dbcon,
              "INSERT INTO TEMPKEY (_pkey) VALUES (?)",
              params = list(object@rows))
    dbClearResult(rs)
    qr <- paste0("UPDATE linktable SET ",
                 "filtered = 0 WHERE _peakpkey IN (",
                 "SELECT _peakpkey FROM peaktable WHERE ",
                 "peaktable.pkey IN (SELECT _pkey FROM TEMPKEY)",
                 " AND (mz NOT BETWEEN ", mz[1],
                 " AND ", mz[2], "))")
    res <- dbSendStatement(dbcon, qr)
    dbClearResult(res)
    dbExecute(dbcon, "DROP TABLE IF EXISTS TEMPKEY")
    object
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterIsolationWindow
setMethod("filterIsolationWindow", "MsBackendSqlDb", {
          function(object, mz = numeric(), ...) {
    if (length(mz)) {
        if (length(mz) > 1)
            stop("'mz' is expected to be a single m/z value", call. = FALSE)
        qry <- dbSendQuery(object@dbcon, paste0("SELECT _pkey FROM ",
                                                object@dbtable,
                                       " WHERE _pkey = $pkey AND ",
                                       "isolationWindowLowerMz <= ", mz,
                                       " AND isolationWindowUpperMz >= ", mz))
        dbBind(qry, list(pkey = object@rows))
        res <- dbFetch(qry)
        dbClearResult(qry)
        object@rows <- res[, 1]
        object
    } else object
  }
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterMsLevel
setMethod("filterMsLevel", "MsBackendSqlDb",
          function(object, msLevel = integer()) {
    if (length(msLevel)) {
        qry <- dbSendQuery(object@dbcon, paste0("SELECT _pkey FROM ",
                                                object@dbtable,
                               " WHERE _pkey = $pkey AND msLevel IN (",
                               paste(msLevel, collapse = ", "), ")"))
        dbBind(qry, list(pkey = object@rows))
        res <- dbFetch(qry)
        dbClearResult(qry)
        object@rows <- res[, 1]
        object
    } else object
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterPolarity
setMethod("filterPolarity", "MsBackendSqlDb",
          function(object, polarity = integer()) {
    if (length(polarity)) {
        qry <- dbSendQuery(object@dbcon, paste0("SELECT _pkey FROM ",
                                                object@dbtable,
                                       " WHERE _pkey = $pkey AND polarity IN (",
                                       paste(polarity, collapse = ", "), ")"))
        dbBind(qry, list(pkey = object@rows))
        res <- dbFetch(qry)
        dbClearResult(qry)
        object@rows <- res[, 1]
        object
    } else object
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterPrecursorMz
setMethod("filterPrecursorMz", "MsBackendSqlDb",
          function(object, mz = numeric()) {
    if (length(mz)) {
        mz <- range(mz)
        keep <- which(precursorMz(object) >= mz[1] &
                      precursorMz(object) <= mz[2])
        object@rows <- object@rows[keep]
        object
    } else object
})



#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterPrecursorScan
setMethod("filterPrecursorScan", "MsBackendSqlDb",
          function(object, acquisitionNum = integer()) {
    if (length(acquisitionNum)) {
        object@rows <- object@rows[Spectra:::.filterSpectraHierarchy(
                                       acquisitionNum(object),
                                       precScanNum(object),
                                       acquisitionNum)]
        object
    } else object
})

#' @rdname hidden_aliases
#'
#' @importMethodsFrom ProtGenerics filterRt
setMethod("filterRt", "MsBackendSqlDb",
          function(object, rt = numeric(), 
                   msLevel. = uniqueMsLevel(object)) {
    if (length(rt)) {
        rt <- range(rt)
        qry <- dbSendQuery(object@dbcon,
                           paste0("SELECT _pkey FROM ", object@dbtable,
                                  " WHERE (_pkey = $pkey AND msLevel NOT IN (",
                                  paste(msLevel., collapse = ", "),
                                  ")) OR (_pkey = $pkey AND ",
                                  "rtime BETWEEN ", rt[1], " AND ", rt[2],
                                  " AND msLevel IN (",
                                  paste(msLevel., collapse = ", "), "))"))
        dbBind(qry, list(pkey = object@rows))
        res <- dbFetch(qry)
        dbClearResult(qry)
        object@rows <- res[, 1]
        object
    } else object
})

#### ---------------------------------------------------------------------------
##
##        Spectra functions: backend-specific methods for MsBackendSql
##
#### ---------------------------------------------------------------------------

#' @export joinSpectraDataSQL
#'
#' @importFrom Spectra Spectra
#' 
#' @rdname hidden_aliases
joinSpectraDataSQL <- function(x, y,
                               by.x = "spectrumId",
                               by.y,
                               suffix.y = ".y",
                               y.table = "annot",
                               dbtable = "NewMSData") {
    stopifnot(inherits(x@backend, "MsBackendSqlDb"))
    stopifnot(inherits(y, "DataFrame"))  
    if (missing(by.y))
        by.y <- by.x
    x_vars <- spectraVariables(x)
    y_vars <- names(y)
    if (length(by.x) != 1 | length(by.y) != 1)
        stop("'by.x' and 'by.y' must be of length 1.")
    if (!is.character(by.x) | !is.character(by.y))
        stop("'by.x' and 'by.y' must be characters.")  # "by.x" shall be implemented to a SQLite statement  
    if (any(duplicated(x_vars)))
        stop("Duplicated spectra variables in 'x'.")
    if (any(duplicated(y_vars)))
        stop("Duplicated names in 'y'.")
    if (!by.x %in% x_vars)
        stop("'by.x' not found in spectra variables.")
    if (!by.y %in% y_vars)
        stop("'by.y' not found.")
    if (dbExistsTable(x@backend@dbcon, y.table))
        stop("Duplicated 'y.table' existing in 'x'.")
    if (dbExistsTable(x@backend@dbcon, dbtable))
        stop("Duplicated 'dbtable' existing in 'x'.")
    ## Don't need by.y anymore
    y_vars_less <- y_vars[-grep(by.y, y_vars)]
    ## Check if there are any shared x_vars and y_vars. If so, the
    ## y_vars are appended suffix.y.
    if (length(xy_vars <- intersect(x_vars, y_vars_less))) {
        y_vars[y_vars %in% xy_vars] <- paste0(y_vars[y_vars %in% xy_vars], suffix.y[1])
        y_vars_less <- y_vars[-grep(by.y, y_vars)]
        names(y) <- y_vars
    }
    ## write y (DataFrame) into SQLite database as the 2nd table: annot
    .write_data_to_db(y, x@backend@dbcon, dbtable = y.table)
    ## Keep only rows that (1) have a non-NA by.y and (2) that are in
    ## x[[by.x]] (given that we do a left join here).
    ## The dbtable in 'x' will left join y.table on the first occurrences
    ## of matching value on 'x'. This will create a SQLite 'View' on the
    ## SQLite backend of 'x'.
    sp_var <- paste(spectraVariables(x@backend), collapse = ", ")
    sp_var_sql <- paste(gsub(by.x, paste0("m.", by.x),
                                   spectraVariables(x@backend)),
                        collapse = ", ")
    str1 <- paste0("CASE WHEN RN = 1 THEN a.'TokenColName' ",
                   "ELSE NULL END AS 'TokenColName',")
    str2 <- lapply(y_vars_less, function(t) gsub("TokenColName", t, str1,
                                                 fixed = TRUE))
    str2 <- paste(str2, collapse = ' ')
    ## parameters are not allowed in SQL views
    nrow <- dbExecute(x@backend@dbcon, paste0("CREATE VIEW ", dbtable,
                                              " AS WITH m AS (SELECT ", sp_var,
                                              ", _pkey, ROW_NUMBER() OVER (",
                                              "PARTITION BY ", by.x,
                                              " ORDER BY _pkey) RN ","FROM ",
                                              x@backend@dbtable, " WHERE _pkey",
                                              " IN (", paste(x@backend@rows,
                                                             collapse = ", "),
                                              ") ) ", "SELECT ", sp_var_sql,
                                              ", ", str2,
                                              " m._pkey ",
                                              "FROM m LEFT JOIN ", y.table,
                                              " AS a ON m.", by.x, " = a.",
                                              by.y, " ORDER BY m._pkey"))
    res <- Spectra(MsBackendSqlDb())
    slot(res@backend, "dbcon", check = FALSE) <- x@backend@dbcon
    ## After join data to 'x', will create a new Spectra obj.
    ## However, 'dbtable' will be a SQLite View instead of a 'Table'
    slot(res@backend, "dbtable", check = FALSE) <- dbtable
    ## `modCount` add 1, for adding `y` to the data table
    slot(res@backend, "modCount", check = FALSE) <- x@backend@modCount + 1L
    ## Use x@rows for this SQLite View
    slot(res@backend, "rows", check = FALSE) <- x@backend@rows
    slot(res@backend, "columns", check = FALSE) <- c(spectraVariables(x@backend),
                                             y_vars_less)
    slot(res@backend, "readonly", check = FALSE) <- x@backend@readonly
    slot(res@backend, "version", check = FALSE) <- x@backend@version
    res
}

#' @export remouldSpecraSQL
#' 
#' @rdname hidden_aliases
remouldSpecraSQL <- function(x) {
    stopifnot(inherits(x, "Spectra"))
    if (!inherits(x@backend, "MsBackendSqlDb"))
        stop("Method can only be used on MsBackendSqlDb.")
    view_ls <- dbGetQuery(x@backend@dbcon,
                          "SELECT NAME FROM sqlite_master WHERE type = 'view';")
    if (!(x@backend@dbtable %in% view_ls[, 1]))
        stop("'x' is not using SQL view.")
    res_var <- spectraVariables(x@backend)
    res_var <- paste(res_var, collapse = ", ")
    tbl_info <- dbGetQuery(x@backend@dbcon, paste0("PRAGMA table_info(",
                                                   x@backend@dbtable, ");"))
    tbl_info$type[tbl_info$name %in% "_pkey"] <- "INTEGER PRIMARY KEY" 
    nrow1 <- dbExecute(x@backend@dbcon, 
                       paste0("create table '", "NewTmpMerged", "' (",
                              paste(paste0("'", tbl_info$name, "'"),
                                    tbl_info$type, collapse = ", "), ")"))
    merged_var <- paste(paste0("[", 
                                tbl_info$name[!(tbl_info$name %in% "_pkey")], 
                                   "]"), collapse = ", ")
    rs1 <- dbSendStatement(x@backend@dbcon,
                               paste0("INSERT INTO '", "NewTmpMerged", "' (",
                                      merged_var, ") SELECT ", merged_var, 
                                      " FROM ", x@backend@dbtable))
    dbClearResult(rs1)
    dbExecute(x@backend@dbcon, paste0("DROP VIEW IF EXISTS ",
                                      x@backend@dbtable))
    dbExecute(x@backend@dbcon, paste0("ALTER TABLE '",
                                      "NewTmpMerged", "' RENAME TO ",
                                      x@backend@dbtable))
    max_pkey <- dbGetQuery(x@backend@dbcon, paste0("SELECT MAX(_pkey) FROM ", 
                                            x@backend@dbtable))
    slot(x@backend, "rows", check = FALSE) <- as.integer(1:max_pkey[[1]])
    x
}
